[2025-04-25 12:16:20] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-25 12:16:20] 开始数据预处理...
[2025-04-25 12:16:20] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-25 12:21:58] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-25 12:21:58] 开始数据预处理...
[2025-04-25 12:21:58] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-25 13:35:12] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-25 13:35:12] 开始数据预处理...
[2025-04-25 13:35:12] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-25 14:38:07] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-25 14:38:07] 开始数据预处理...
[2025-04-25 14:38:07] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-26 20:35:58] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-26 20:35:58] 开始数据预处理...
[2025-04-26 20:35:58] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-27 21:43:28] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-27 21:43:28] 开始数据预处理...
[2025-04-27 21:43:29] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-28 16:52:36] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 16:52:36] 开始数据预处理...
[2025-04-28 16:52:36] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-28 16:58:04] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 16:58:04] 开始数据预处理...
[2025-04-28 16:58:04] 数据预处理失败: Expecting ':' delimiter: line 1 column 2327273 (char 2327272)
[2025-04-28 17:09:48] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 17:09:48] 开始数据预处理...
[2025-04-28 17:09:50] 数据预处理失败: Unterminated string starting at: line 1 column 2327269 (char 2327268)
[2025-04-28 17:10:28] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 17:10:28] 开始数据预处理...
[2025-04-28 17:10:29] 数据预处理失败: Unterminated string starting at: line 1 column 2327269 (char 2327268)
[2025-04-28 17:12:16] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 17:12:16] 开始数据预处理...
[2025-04-28 17:12:22] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 17:12:22] 划分数据集...
[2025-04-28 17:12:25] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 17:12:25] 开始特征工程...
[2025-04-28 17:12:31] 特征工程失败: No module named 'networkx'
[2025-04-28 17:12:42] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 17:12:42] 开始数据预处理...
[2025-04-28 17:12:47] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 17:12:47] 划分数据集...
[2025-04-28 17:12:50] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 17:12:50] 开始特征工程...
[2025-04-28 17:12:55] 特征工程失败: No module named 'networkx'
[2025-04-28 17:13:37] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 17:13:37] 开始数据预处理...
[2025-04-28 17:13:45] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 17:13:45] 划分数据集...
[2025-04-28 17:13:48] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 17:13:48] 开始特征工程...
[2025-04-28 17:14:51] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 17:14:51] 开始构建模型...
[2025-04-28 17:14:54] 模型训练与评估失败: Unable to allocate 7.11 GiB for an array with shape (7166, 1065765) and data type bool
[2025-04-28 17:14:54] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 58, in prepare_data
    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\reshape\encoding.py", line 224, in get_dummies
    result = concat(with_dummies, axis=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\reshape\concat.py", line 395, in concat
    return op.get_result()
           ^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\reshape\concat.py", line 684, in get_result
    new_data = concatenate_managers(
               ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\internals\concat.py", line 131, in concatenate_managers
    mgrs = _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\internals\concat.py", line 230, in _maybe_reindex_columns_na_proxy
    mgr = mgr.copy()
          ^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 593, in copy
    res = self.apply("copy", deep=deep)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 363, in apply
    applied = getattr(b, f)(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\internals\blocks.py", line 796, in copy
    values = values.copy()
             ^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 7.11 GiB for an array with shape (7166, 1065765) and data type bool

[2025-04-28 19:04:31] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:04:31] 开始数据预处理...
[2025-04-28 19:04:36] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:04:36] 划分数据集...
[2025-04-28 19:04:39] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:04:39] 开始特征工程...
[2025-04-28 19:05:32] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:05:32] 开始构建模型...
[2025-04-28 19:05:35] 模型训练与评估失败: Unable to allocate 56.9 GiB for an array with shape (1065765, 7167) and data type float64
[2025-04-28 19:05:35] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 53, in prepare_data
    encoded = np.zeros((len(X), len(unique_values)))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 56.9 GiB for an array with shape (1065765, 7167) and data type float64

[2025-04-28 19:07:58] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:07:58] 开始数据预处理...
[2025-04-28 19:08:03] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:08:03] 划分数据集...
[2025-04-28 19:08:06] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:08:06] 开始特征工程...
[2025-04-28 19:09:00] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:09:00] 开始构建模型...
[2025-04-28 19:09:02] 模型训练与评估失败: Unable to allocate 56.9 GiB for an array with shape (1065765, 7167) and data type float64
[2025-04-28 19:09:02] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 52, in prepare_data
    encoded = np.zeros((len(X), len(unique_values)))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 56.9 GiB for an array with shape (1065765, 7167) and data type float64

[2025-04-28 19:09:45] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:09:45] 开始数据预处理...
[2025-04-28 19:09:50] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:09:50] 划分数据集...
[2025-04-28 19:09:53] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:09:53] 开始特征工程...
[2025-04-28 19:10:47] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:10:47] 开始构建模型...
[2025-04-28 19:10:49] 模型训练与评估失败: Unable to allocate 56.9 GiB for an array with shape (1065765, 7167) and data type float64
[2025-04-28 19:10:49] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 52, in prepare_data
    encoded = np.zeros((len(X), len(unique_values)))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 56.9 GiB for an array with shape (1065765, 7167) and data type float64

[2025-04-28 19:12:59] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:12:59] 开始数据预处理...
[2025-04-28 19:13:04] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:13:04] 划分数据集...
[2025-04-28 19:13:06] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:13:06] 开始特征工程...
[2025-04-28 19:13:59] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:13:59] 开始构建模型...
[2025-04-28 19:14:02] 模型训练与评估失败: Unable to allocate 28.5 GiB for an array with shape (1065765, 7167) and data type float32
[2025-04-28 19:14:02] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 52, in prepare_data
    encoded = np.zeros((len(X), len(unique_values)), dtype=np.float32)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 28.5 GiB for an array with shape (1065765, 7167) and data type float32

[2025-04-28 19:14:43] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:14:43] 开始数据预处理...
[2025-04-28 19:14:48] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:14:48] 划分数据集...
[2025-04-28 19:14:50] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:14:50] 开始特征工程...
[2025-04-28 19:15:43] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:15:43] 开始构建模型...
[2025-04-28 19:15:47] 模型训练与评估失败: could not convert string to float: 'cb1944869876fa70d20fcae21e14f45d'
[2025-04-28 19:15:47] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 76, in prepare_data
    X_num = pd.DataFrame(self.scaler.fit_transform(X_num), columns=num_cols)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\_set_output.py", line 319, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 918, in fit_transform
    return self.fit(X, **fit_params).transform(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\preprocessing\_data.py", line 894, in fit
    return self.partial_fit(X, y, sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\preprocessing\_data.py", line 930, in partial_fit
    X = validate_data(
        ^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 2944, in validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1055, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\_array_api.py", line 839, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\pandas\core\generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: could not convert string to float: 'cb1944869876fa70d20fcae21e14f45d'

[2025-04-28 19:16:54] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:16:54] 开始数据预处理...
[2025-04-28 19:16:59] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:16:59] 划分数据集...
[2025-04-28 19:17:01] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:17:01] 开始特征工程...
[2025-04-28 19:17:52] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:17:52] 开始构建模型...
[2025-04-28 19:18:00] 模型训练与评估失败: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>)
[2025-04-28 19:18:00] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 87, in prepare_data
    X_num = pd.DataFrame(self.scaler.fit_transform(X_num), columns=num_cols)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\_set_output.py", line 319, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 918, in fit_transform
    return self.fit(X, **fit_params).transform(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\preprocessing\_data.py", line 894, in fit
    return self.partial_fit(X, y, sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\preprocessing\_data.py", line 930, in partial_fit
    X = validate_data(
        ^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 2944, in validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 931, in check_array
    dtype_orig = np.result_type(*dtypes_orig)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.DTypePromotionError: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>)

[2025-04-28 19:18:37] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:18:37] 开始数据预处理...
[2025-04-28 19:18:41] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:18:41] 划分数据集...
[2025-04-28 19:18:44] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:18:44] 开始特征工程...
[2025-04-28 19:19:34] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:19:34] 开始构建模型...
[2025-04-28 19:19:45] 模型训练与评估失败: object of type 'NoneType' has no len()
[2025-04-28 19:19:45] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 85, in main
    log(f"准备训练数据完成，特征数量: {len(feature_names)}")
                                       ^^^^^^^^^^^^^^^^^^
TypeError: object of type 'NoneType' has no len()

[2025-04-28 19:22:00] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:22:00] 开始数据预处理...
[2025-04-28 19:22:04] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:22:04] 划分数据集...
[2025-04-28 19:22:06] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:22:06] 开始特征工程...
[2025-04-28 19:22:56] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:22:56] 开始构建模型...
[2025-04-28 19:23:07] 准备训练数据完成，特征数量: 7263
[2025-04-28 19:23:07] 训练逻辑回归模型...
[2025-04-28 19:23:07] 模型训练与评估失败: Unable to allocate 46.1 GiB for an array with shape (852612, 7263) and data type float64
[2025-04-28 19:23:07] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 90, in main
    model_builder.build_logistic_regression(X_train, y_train)
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 124, in build_logistic_regression
    X_train = X_train.toarray()
              ^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_compressed.py", line 1170, in toarray
    out = self._process_toarray_args(order, out)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_base.py", line 1367, in _process_toarray_args
    return np.zeros(self.shape, dtype=self.dtype, order=order)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 46.1 GiB for an array with shape (852612, 7263) and data type float64

[2025-04-28 19:25:13] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:25:13] 开始数据预处理...
[2025-04-28 19:25:18] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:25:18] 划分数据集...
[2025-04-28 19:25:20] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:25:20] 开始特征工程...
[2025-04-28 19:26:10] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:26:10] 开始构建模型...
[2025-04-28 19:26:21] 准备训练数据完成，特征数量: 7263
[2025-04-28 19:26:21] 训练逻辑回归模型...
[2025-04-28 19:26:21] 模型训练与评估失败: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
[2025-04-28 19:26:21] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 90, in main
    model_builder.build_logistic_regression(X_train, y_train)
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 131, in build_logistic_regression
    model.fit(X_train, y_train)
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py", line 1222, in fit
    X, y = validate_data(
           ^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1370, in check_X_y
    X = check_array(
        ^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1014, in check_array
    array = _ensure_sparse_format(
            ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 649, in _ensure_sparse_format
    _assert_all_finite(
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

[2025-04-28 19:55:42] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:55:42] 开始数据预处理...
[2025-04-28 19:55:46] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:55:46] 划分数据集...
[2025-04-28 19:55:48] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:55:48] 开始特征工程...
[2025-04-28 19:56:39] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 19:56:39] 开始构建模型...
[2025-04-28 19:56:51] 准备训练数据完成，特征数量: 7263
[2025-04-28 19:56:51] 训练逻辑回归模型...
[2025-04-28 19:56:51] 模型训练与评估失败: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
[2025-04-28 19:56:51] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 90, in main
    model_builder.build_logistic_regression(X_train, y_train)
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 134, in build_logistic_regression
    model.fit(X_train, y_train)
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py", line 1222, in fit
    X, y = validate_data(
           ^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1370, in check_X_y
    X = check_array(
        ^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1014, in check_array
    array = _ensure_sparse_format(
            ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 649, in _ensure_sparse_format
    _assert_all_finite(
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

[2025-04-28 19:59:41] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 19:59:41] 开始数据预处理...
[2025-04-28 19:59:46] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 19:59:46] 划分数据集...
[2025-04-28 19:59:48] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 19:59:48] 开始特征工程...
[2025-04-28 20:00:38] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 20:00:38] 开始构建模型...
[2025-04-28 20:00:50] 模型训练与评估失败: Unable to allocate 57.7 GiB for an array with shape (1065765, 7263) and data type float64
[2025-04-28 20:00:50] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 83, in main
    X_train, X_val, y_train, y_val, feature_names = model_builder.prepare_data(train_features, test_size=args.val_size)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 117, in prepare_data
    X_dense = X.toarray()
              ^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_compressed.py", line 1170, in toarray
    out = self._process_toarray_args(order, out)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_base.py", line 1367, in _process_toarray_args
    return np.zeros(self.shape, dtype=self.dtype, order=order)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 57.7 GiB for an array with shape (1065765, 7263) and data type float64

[2025-04-28 20:06:52] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-04-28 20:06:52] 开始数据预处理...
[2025-04-28 20:06:56] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-04-28 20:06:56] 划分数据集...
[2025-04-28 20:06:58] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-04-28 20:06:58] 开始特征工程...
[2025-04-28 20:07:50] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-04-28 20:07:50] 开始构建模型...
[2025-04-28 20:08:03] 准备训练数据完成，特征数量: 7263
[2025-04-28 20:08:03] 训练逻辑回归模型...
[2025-05-01 10:31:24] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 10:31:24] 开始数据预处理...
[2025-05-01 10:31:31] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 10:31:31] 划分数据集...
[2025-05-01 10:31:37] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 10:31:37] 开始特征工程...
[2025-05-01 10:32:37] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 10:32:37] 开始构建模型...
[2025-05-01 10:32:52] 准备训练数据完成，特征数量: 7263
[2025-05-01 10:32:52] 训练逻辑回归模型...
[2025-05-01 10:34:56] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 10:34:56] 开始数据预处理...
[2025-05-01 10:35:02] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 10:35:02] 划分数据集...
[2025-05-01 10:35:05] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 10:35:05] 开始特征工程...
[2025-05-01 10:36:06] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 10:36:06] 开始构建模型...
[2025-05-01 10:36:23] 准备训练数据完成，特征数量: 7263
[2025-05-01 10:36:23] 训练逻辑回归模型...
[2025-05-01 10:40:28] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 10:40:28] 开始数据预处理...
[2025-05-01 10:40:34] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 10:40:34] 划分数据集...
[2025-05-01 10:40:36] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 10:40:36] 开始特征工程...
[2025-05-01 10:41:39] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 10:41:39] 开始构建模型...
[2025-05-01 10:41:56] 准备训练数据完成，特征数量: 7263
[2025-05-01 10:41:56] 训练逻辑回归模型...
[2025-05-01 11:06:21] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:06:21] 开始数据预处理...
[2025-05-01 11:06:26] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:06:26] 划分数据集...
[2025-05-01 11:06:28] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:06:28] 开始特征工程...
[2025-05-01 11:07:22] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:07:22] 开始构建模型...
[2025-05-01 11:07:35] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:07:35] 训练逻辑回归模型...
[2025-05-01 11:09:43] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:09:43] 开始数据预处理...
[2025-05-01 11:09:48] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:09:48] 划分数据集...
[2025-05-01 11:09:50] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:09:50] 开始特征工程...
[2025-05-01 11:10:44] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:10:44] 开始构建模型...
[2025-05-01 11:10:58] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:10:58] 训练逻辑回归模型...
[2025-05-01 11:21:43] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:21:43] 开始数据预处理...
[2025-05-01 11:21:49] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:21:49] 划分数据集...
[2025-05-01 11:21:52] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:21:52] 开始特征工程...
[2025-05-01 11:23:18] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:23:18] 开始构建模型...
[2025-05-01 11:23:42] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:23:42] 训练逻辑回归模型...
[2025-05-01 11:26:47] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:26:47] 开始数据预处理...
[2025-05-01 11:26:53] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:26:53] 划分数据集...
[2025-05-01 11:26:56] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:26:56] 开始特征工程...
[2025-05-01 11:28:14] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:28:14] 开始构建模型...
[2025-05-01 11:28:32] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:28:32] 训练逻辑回归模型...
[2025-05-01 11:40:24] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:40:24] 开始数据预处理...
[2025-05-01 11:40:30] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:40:30] 划分数据集...
[2025-05-01 11:40:33] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:40:33] 开始特征工程...
[2025-05-01 11:41:49] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:41:49] 开始构建模型...
[2025-05-01 11:42:06] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:42:06] 训练逻辑回归模型...
[2025-05-01 11:42:06] 模型训练与评估失败: Nested use of alive_progress is not yet supported.
[2025-05-01 11:42:06] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 114, in main
    with alive_bar(title='训练逻辑回归') as progress_bar:
  File "D:\python\Lib\contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\alive_progress\core\progress.py", line 247, in __alive_bar
    hook_manager = buffered_hook_manager(header if config.enrich_print else '',
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\alive_progress\core\hook_manager.py", line 121, in buffered_hook_manager
    raise UserWarning('Nested use of alive_progress is not yet supported.')
UserWarning: Nested use of alive_progress is not yet supported.

[2025-05-01 11:44:38] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['lr', 'rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:44:38] 开始数据预处理...
[2025-05-01 11:44:44] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:44:44] 划分数据集...
[2025-05-01 11:44:47] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:44:47] 开始特征工程...
[2025-05-01 11:46:06] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:46:06] 开始构建模型...
[2025-05-01 11:46:26] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:46:26] 训练逻辑回归模型...
[2025-05-01 11:52:04] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, output_dir='output')
[2025-05-01 11:52:04] 开始数据预处理...
[2025-05-01 11:52:11] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:52:11] 划分数据集...
[2025-05-01 11:52:14] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:52:14] 开始特征工程...
[2025-05-01 11:53:32] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:53:32] 开始构建模型...
[2025-05-01 11:53:50] 准备训练数据完成，特征数量: 7263
[2025-05-01 11:53:50] 训练随机森林模型...
[2025-05-01 11:53:50] 模型训练与评估失败: Unable to allocate 46.1 GiB for an array with shape (852612, 7263) and data type float64
[2025-05-01 11:53:50] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 107, in main
    model_builder.build_random_forest(X_train, y_train)
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 153, in build_random_forest
    X_train = X_train.toarray()
              ^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_compressed.py", line 1170, in toarray
    out = self._process_toarray_args(order, out)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_base.py", line 1367, in _process_toarray_args
    return np.zeros(self.shape, dtype=self.dtype, order=order)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 46.1 GiB for an array with shape (852612, 7263) and data type float64

[2025-05-01 11:56:02] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=50, max_features=0.3, max_depth=20, use_feature_selection=False, feature_percentile=30, output_dir='output')
[2025-05-01 11:56:02] 开始数据预处理...
[2025-05-01 11:56:08] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:56:08] 划分数据集...
[2025-05-01 11:56:11] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:56:11] 开始特征工程...
[2025-05-01 11:57:27] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:57:27] 开始构建模型...
[2025-05-01 11:57:27] 模型训练与评估失败: ModelBuilder.__init__() got an unexpected keyword argument 'max_features'
[2025-05-01 11:57:27] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 89, in main
    model_builder = ModelBuilder(random_state=args.random_state,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ModelBuilder.__init__() got an unexpected keyword argument 'max_features'

[2025-05-01 11:57:50] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=30, max_features=0.2, max_depth=15, use_feature_selection=True, feature_percentile=30, output_dir='output')
[2025-05-01 11:57:50] 开始数据预处理...
[2025-05-01 11:57:56] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 11:57:56] 划分数据集...
[2025-05-01 11:57:59] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 11:57:59] 开始特征工程...
[2025-05-01 11:59:15] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 11:59:15] 开始构建模型...
[2025-05-01 11:59:15] 模型训练与评估失败: ModelBuilder.__init__() got an unexpected keyword argument 'max_features'
[2025-05-01 11:59:15] Traceback (most recent call last):
  File "D:\Pycharm Projact\ReturnOfProductUsers\main.py", line 89, in main
    model_builder = ModelBuilder(random_state=args.random_state,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ModelBuilder.__init__() got an unexpected keyword argument 'max_features'

[2025-05-01 12:01:40] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=50, max_features=0.3, max_depth=20, use_feature_selection=False, feature_percentile=30, output_dir='output')
[2025-05-01 12:01:40] 开始数据预处理...
[2025-05-01 12:01:46] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 12:01:46] 划分数据集...
[2025-05-01 12:01:49] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 12:01:49] 开始特征工程...
[2025-05-01 12:03:05] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 12:03:05] 开始构建模型...
[2025-05-01 12:03:22] 准备训练数据完成，特征数量: 7263
[2025-05-01 12:03:23] 训练随机森林模型...
[2025-05-01 12:03:23] 随机森林模型训练失败: ModelBuilder.build_random_forest() got an unexpected keyword argument 'n_estimators'
[2025-05-01 12:03:23] 训练GBDT模型...
[2025-05-01 12:03:23] 模型训练与评估失败: Unable to allocate 46.1 GiB for an array with shape (852612, 7263) and data type float64
[2025-05-01 12:03:23] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 168, in main
    model_builder.build_gbdt(X_train, y_train)
  File "d:\Pycharm Projact\ReturnOfProductUsers\model_building.py", line 180, in build_gbdt
    X_train = X_train.toarray()
              ^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_compressed.py", line 1170, in toarray
    out = self._process_toarray_args(order, out)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\scipy\sparse\_base.py", line 1367, in _process_toarray_args
    return np.zeros(self.shape, dtype=self.dtype, order=order)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._ArrayMemoryError: Unable to allocate 46.1 GiB for an array with shape (852612, 7263) and data type float64

[2025-05-01 12:06:12] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=50, max_features=0.3, max_depth=20, use_feature_selection=False, feature_percentile=30, output_dir='output')
[2025-05-01 12:06:12] 开始数据预处理...
[2025-05-01 12:06:17] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 12:06:17] 划分数据集...
[2025-05-01 12:06:19] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 12:06:19] 开始特征工程...
[2025-05-01 12:07:12] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 12:07:12] 开始构建模型...
[2025-05-01 12:07:25] 准备训练数据完成，特征数量: 7263
[2025-05-01 12:18:21] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=50, max_features=0.3, max_depth=20, use_feature_selection=False, feature_percentile=30, output_dir='output')
[2025-05-01 12:18:21] 开始数据预处理...
[2025-05-01 12:18:26] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-01 12:18:26] 划分数据集...
[2025-05-01 12:18:28] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-01 12:18:28] 开始特征工程...
[2025-05-01 12:19:22] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-01 12:19:22] 开始构建模型...
[2025-05-01 12:19:34] 准备训练数据完成，特征数量: 7263
[2025-05-08 19:01:13] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=50, max_features=0.3, max_depth=20, use_feature_selection=False, feature_percentile=30, output_dir='output')
[2025-05-08 19:01:13] 开始数据预处理...
[2025-05-08 19:01:19] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-08 19:01:19] 划分数据集...
[2025-05-08 19:01:21] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-08 19:01:21] 开始特征工程...
[2025-05-08 19:02:14] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, models=['rf', 'gbdt', 'lgb', 'xgb', 'dnn', 'lstm'], top_k=10, random_state=42, n_estimators=50, max_features=0.3, max_depth=20, use_feature_selection=False, feature_percentile=30, output_dir='output')
[2025-05-08 19:02:14] 开始数据预处理...
[2025-05-08 19:02:20] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-08 19:02:20] 划分数据集...
[2025-05-08 19:02:23] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-08 19:02:23] 开始特征工程...
[2025-05-08 19:02:49] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-08 19:02:49] 开始构建模型...
[2025-05-08 19:03:35] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-08 19:03:35] 开始构建模型...
[2025-05-17 11:50:04] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, limit_features=False, feature_count=100, use_bayesian_opt=False, bayesian_iter=20, epochs=50, random_state=42, output_dir='output')
[2025-05-17 11:50:04] 开始数据预处理...
[2025-05-17 11:50:10] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 11:50:10] 划分数据集...
[2025-05-17 11:50:13] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 11:50:13] 开始特征工程...
[2025-05-17 11:51:14] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-17 11:51:14] 准备模型训练数据...
[2025-05-17 11:51:18] 数据准备失败: could not convert string to float: '95955edfedfcf40e4fc4562f31b7dd87'
[2025-05-17 11:51:18] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 432, in main
    X_train_scaled = scaler.fit_transform(X_train)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\_set_output.py", line 319, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 918, in fit_transform
    return self.fit(X, **fit_params).transform(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\preprocessing\_data.py", line 894, in fit
    return self.partial_fit(X, y, sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\preprocessing\_data.py", line 930, in partial_fit
    X = validate_data(
        ^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 2944, in validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1055, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Pycharm Projact\ReturnOfProductUsers\.venv\Lib\site-packages\sklearn\utils\_array_api.py", line 839, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: could not convert string to float: '95955edfedfcf40e4fc4562f31b7dd87'

[2025-05-17 11:54:14] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, limit_features=False, feature_count=100, use_bayesian_opt=False, bayesian_iter=20, epochs=50, random_state=42, model_type='classification', force_binary=False, output_dir='output')
[2025-05-17 11:54:14] 开始数据预处理...
[2025-05-17 11:54:18] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 11:54:18] 划分数据集...
[2025-05-17 11:54:21] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 11:54:21] 开始特征工程...
[2025-05-17 11:55:18] 特征工程完成，训练集特征数量: 60, 测试集特征数量: 60
[2025-05-17 11:55:18] 准备模型训练数据...
[2025-05-17 11:55:18] 检查特征类型...
[2025-05-17 11:55:18] 发现非数值特征: user_id, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: user_id_voter, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: cate_id, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: cate_level1_id, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: brand_id, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: shop_id, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: user_id_inviter_graph, 类型: object
[2025-05-17 11:55:18] 发现非数值特征: user_id_voter_graph, 类型: object
[2025-05-17 11:55:18] 需要处理 8 个非数值特征列
[2025-05-17 11:55:18] 对列 'user_id' 进行标签编码
[2025-05-17 11:55:18] 对列 'user_id_voter' 进行标签编码
[2025-05-17 11:55:18] 对列 'cate_id' 进行标签编码
[2025-05-17 11:55:19] 对列 'cate_level1_id' 进行标签编码
[2025-05-17 11:55:19] 对列 'brand_id' 进行标签编码
[2025-05-17 11:55:20] 对列 'shop_id' 进行标签编码
[2025-05-17 11:55:20] 对列 'user_id_inviter_graph' 进行标签编码
[2025-05-17 11:55:21] 对列 'user_id_voter_graph' 进行标签编码
[2025-05-17 11:55:21] 标签编码器已保存到: output\models\label_encoders.pkl
[2025-05-17 11:55:21] 分离特征和标签...
[2025-05-17 11:55:21] 将voter_id转换为数值类型...
[2025-05-17 11:55:23] 转换为分类问题，类别数量: 96072
[2025-05-17 11:55:23] 类别数量过多，使用整数标签
[2025-05-17 11:55:25] 数据准备完成，训练集大小: (852612, 56), 验证集大小: (213153, 56), 测试集大小: (155824, 56)
[2025-05-17 11:55:25] 开始贝叶斯优化超参数...
[2025-05-17 11:55:25] 跳过贝叶斯优化，使用默认超参数
[2025-05-17 11:55:25] 开始训练CNN+LSTM模型...
[2025-05-17 11:55:27] 序列数据准备完成，形状: (852608, 5, 56)
[2025-05-17 11:55:27] 类别数量过多(72513)，将作为回归问题处理
[2025-05-17 11:55:27] 开始训练模型...
[2025-05-17 13:39:15] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_lstm=False, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 13:39:15] 开始数据预处理...
[2025-05-17 13:39:20] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 13:39:20] 划分数据集...
[2025-05-17 13:39:22] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 13:39:22] 构建社交图谱...
[2025-05-17 13:39:22] 图构建失败: name 'build_graph_from_interactions' is not defined
[2025-05-17 13:39:22] Traceback (most recent call last):
  File "d:\Pycharm Projact\ReturnOfProductUsers\main.py", line 576, in main
    G, node_mapping, node_features = build_graph_from_interactions(train_df, user_info_df, item_info_df)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'build_graph_from_interactions' is not defined

[2025-05-17 13:55:23] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_lstm=False, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 13:55:23] 开始数据预处理...
[2025-05-17 13:55:28] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 13:55:28] 划分数据集...
[2025-05-17 13:55:31] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 13:55:31] 构建社交图谱...
[2025-05-17 15:30:18] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 15:30:18] 开始数据预处理...
[2025-05-17 15:30:21] 数据集规模降低: 从 602679 到 30134 记录 (1/20)
[2025-05-17 15:30:21] 减少后的用户数量: 20539, 物品数量: 25364
[2025-05-17 15:30:21] 数据预处理完成，商品分享记录数量: 30134, 用户数量: 20539, 商品数量: 25364
[2025-05-17 15:30:21] 划分数据集...
[2025-05-17 15:30:21] 数据集划分完成，训练集大小: 24107, 测试集大小: 6027
[2025-05-17 15:30:21] 构建社交图谱...
[2025-05-17 15:30:50] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 15:30:50] 开始数据预处理...
[2025-05-17 15:30:52] 数据集规模降低: 从 602679 到 30134 记录 (1/20)
[2025-05-17 15:30:52] 减少后的用户数量: 20539, 物品数量: 25364
[2025-05-17 15:30:52] 数据预处理完成，商品分享记录数量: 30134, 用户数量: 20539, 商品数量: 25364
[2025-05-17 15:30:52] 划分数据集...
[2025-05-17 15:30:52] 数据集划分完成，训练集大小: 24107, 测试集大小: 6027
[2025-05-17 15:30:52] 构建社交图谱...
[2025-05-17 15:32:00] 图构建完成，节点数: 38607, 边数: 45509
[2025-05-17 15:32:00] 准备链接预测数据...
[2025-05-17 15:38:20] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 15:38:20] 开始数据预处理...
[2025-05-17 15:38:23] 数据集规模降低: 从 602679 到 30134 记录 (1/20)
[2025-05-17 15:38:23] 减少后的用户数量: 20539, 物品数量: 25364
[2025-05-17 15:38:23] 数据预处理完成，商品分享记录数量: 30134, 用户数量: 20539, 商品数量: 25364
[2025-05-17 15:38:23] 划分数据集...
[2025-05-17 15:38:23] 数据集划分完成，训练集大小: 24107, 测试集大小: 6027
[2025-05-17 15:38:23] 构建社交图谱...
[2025-05-17 15:39:41] 图构建完成，节点数: 38607, 边数: 45509
[2025-05-17 15:39:41] 准备链接预测数据...
[2025-05-17 15:44:00] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 15:44:00] 开始数据预处理...
[2025-05-17 15:44:02] 数据集规模降低: 从 602679 到 30134 记录 (1/20)
[2025-05-17 15:44:03] 减少后的用户数量: 20539, 物品数量: 25364
[2025-05-17 15:44:03] 数据预处理完成，商品分享记录数量: 30134, 用户数量: 20539, 商品数量: 25364
[2025-05-17 15:44:03] 划分数据集...
[2025-05-17 15:44:03] 数据集划分完成，训练集大小: 24107, 测试集大小: 6027
[2025-05-17 15:44:03] 构建社交图谱...
[2025-05-17 15:45:14] 图构建完成，节点数: 38607, 边数: 45509
[2025-05-17 15:45:14] 准备链接预测数据...
[2025-05-17 15:49:51] 链接预测数据准备完成，训练样本: 115569, 验证样本: 28901
[2025-05-17 15:49:51] 训练GNN模型...
[2025-05-17 15:49:51] 使用减少的训练轮数: 50 (原计划: 100)
[2025-05-17 15:49:52] Epoch 5/50, Loss: 0.6541, Val Loss: 0.6489, Val Acc: 0.6663
[2025-05-17 15:49:53] Epoch 10/50, Loss: 0.6387, Val Loss: 0.6386, Val Acc: 0.6663
[2025-05-17 15:49:54] 早停: 5 个epoch内验证损失没有改善
[2025-05-17 15:49:54] GNN模型训练完成
[2025-05-17 15:49:54] 训练XGBoost模型...
[2025-05-17 15:49:54] 混合模型训练完成
[2025-05-17 15:49:54] 总候选用户数量: 20539
[2025-05-17 15:49:54] 从测试集中随机抽取 100 条记录进行验证
[2025-05-17 15:50:18] 预测完成，生成了 100 个预测结果
[2025-05-17 15:50:18] 计算MRR (Mean Reciprocal Rank)...
[2025-05-17 15:50:18] 测试样本上的MRR: 0.0000
[2025-05-17 15:50:18] 实验完成，总运行时间: 377.88秒 (6.30分钟)
[2025-05-17 16:03:44] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 16:03:44] 开始数据预处理...
[2025-05-17 16:03:46] 使用完整数据集: 602679 条记录
[2025-05-17 16:03:49] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 16:03:49] 划分数据集...
[2025-05-17 16:03:52] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 16:03:52] 构建社交图谱...
[2025-05-17 17:47:21] 图构建完成，节点数: 365505, 边数: 791734
[2025-05-17 17:47:21] 准备链接预测数据...
[2025-05-17 20:53:16] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 20:53:16] 开始数据预处理...
[2025-05-17 20:53:19] 使用完整数据集: 602679 条记录
[2025-05-17 20:53:31] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 20:53:31] 划分数据集...
[2025-05-17 20:53:35] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 20:53:35] 构建社交图谱...
[2025-05-17 20:54:02] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-17 20:54:02] 开始数据预处理...
[2025-05-17 20:54:05] 使用完整数据集: 602679 条记录
[2025-05-17 20:54:09] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-17 20:54:09] 划分数据集...
[2025-05-17 20:54:12] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-17 20:54:12] 构建社交图谱...
[2025-05-18 13:08:42] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:08:42] 开始数据预处理...
[2025-05-18 13:08:42] 数据预处理失败: [Errno 2] No such file or directory: 'train/preliminary\\item_share_train_info.json'
[2025-05-18 13:09:57] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:09:57] 开始数据预处理...
[2025-05-18 13:09:57] 数据预处理失败: [Errno 2] No such file or directory: 'train/preliminary\\item_share_train_info.json'
[2025-05-18 13:17:42] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:17:42] 开始数据预处理...
[2025-05-18 13:17:44] 使用完整数据集: 602679 条记录
[2025-05-18 13:17:47] 数据预处理完成，商品分享记录数量: 602679, 用户数量: 115849, 商品数量: 438164
[2025-05-18 13:17:47] 划分数据集...
[2025-05-18 13:17:50] 数据集划分完成，训练集大小: 482143, 测试集大小: 120536
[2025-05-18 13:17:50] 构建社交图谱...
[2025-05-18 13:24:59] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:24:59] 开始数据预处理...
[2025-05-18 13:24:59] 加载训练集文件: train/preliminary/item_share_train_info.json
[2025-05-18 13:25:00] 加载测试集文件: test/preliminary/item_share_preliminary_test_info.json
[2025-05-18 13:25:01] 加载用户信息文件: train/preliminary/user_info.json
[2025-05-18 13:25:01] 加载物品信息文件: train/preliminary/item_info.json
[2025-05-18 13:25:02] 对数据进行预处理...
[2025-05-18 13:25:02] 数据预处理失败: invalid literal for int() with base 10: '5113da4ea98c5b38de164f4ee7a68d56'
[2025-05-18 13:28:02] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=False, sampling_rate=0.3, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:28:02] 开始数据预处理...
[2025-05-18 13:28:02] 加载训练集文件: train/preliminary/item_share_train_info.json
[2025-05-18 13:28:04] 加载测试集文件: test/preliminary/item_share_preliminary_test_info.json
[2025-05-18 13:28:04] 加载用户信息文件: train/preliminary/user_info.json
[2025-05-18 13:28:04] 加载物品信息文件: train/preliminary/item_info.json
[2025-05-18 13:28:05] 对数据进行预处理...
[2025-05-18 13:28:09] 数据预处理完成，商品分享训练记录数量: 602679, 测试记录数量: 118424, 用户数量: 115849, 商品数量: 438164
[2025-05-18 13:28:09] 使用预定义的训练集和测试集...
[2025-05-18 13:28:09] 构建社交图谱...
[2025-05-18 13:28:55] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=True, sampling_rate=0.1, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:28:55] 开始数据预处理...
[2025-05-18 13:28:55] 加载训练集文件: train/preliminary/item_share_train_info.json
[2025-05-18 13:28:57] 加载测试集文件: test/preliminary/item_share_preliminary_test_info.json
[2025-05-18 13:28:57] 加载用户信息文件: train/preliminary/user_info.json
[2025-05-18 13:28:57] 加载物品信息文件: train/preliminary/item_info.json
[2025-05-18 13:28:59] 对数据进行预处理...
[2025-05-18 13:29:03] 数据预处理完成，商品分享训练记录数量: 602679, 测试记录数量: 118424, 用户数量: 115849, 商品数量: 438164
[2025-05-18 13:29:03] 使用预定义的训练集和测试集...
[2025-05-18 13:29:03] 构建社交图谱...
[2025-05-18 13:29:38] 开始执行实验，参数配置：Namespace(test_size=0.2, val_size=0.2, use_sampling=True, sampling_rate=0.05, gnn_type='sage', hidden_channels=128, embedding_dim=64, dropout=0.2, learning_rate=0.001, epochs=100, use_xgboost=False, random_state=42, output_dir='output')
[2025-05-18 13:29:38] 开始数据预处理...
[2025-05-18 13:29:38] 加载训练集文件: train/preliminary/item_share_train_info.json
[2025-05-18 13:29:40] 加载测试集文件: test/preliminary/item_share_preliminary_test_info.json
[2025-05-18 13:29:40] 加载用户信息文件: train/preliminary/user_info.json
[2025-05-18 13:29:41] 加载物品信息文件: train/preliminary/item_info.json
[2025-05-18 13:29:42] 对训练数据进行采样，采样率: 0.05, 原始数据量: 602679
[2025-05-18 13:29:42] 采样后的训练数据量: 30134
[2025-05-18 13:29:42] 过滤用户信息，原始用户数量: 115849
[2025-05-18 13:29:42] 过滤后的用户数量: 20539
[2025-05-18 13:29:42] 过滤物品信息，原始物品数量: 438164
[2025-05-18 13:29:42] 过滤后的物品数量: 25364
[2025-05-18 13:29:42] 对数据进行预处理...
[2025-05-18 13:29:43] 数据预处理完成，商品分享训练记录数量: 30134, 测试记录数量: 118424, 用户数量: 20539, 商品数量: 25364
[2025-05-18 13:29:43] 使用预定义的训练集和测试集...
[2025-05-18 13:29:43] 构建社交图谱...
[2025-05-18 13:31:22] 图构建完成，节点数: 45903, 边数: 56461
[2025-05-18 13:31:22] 准备链接预测数据...
